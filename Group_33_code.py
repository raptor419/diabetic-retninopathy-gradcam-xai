# -*- coding: utf-8 -*-
"""ResnetCAM_Test.ipynb

Generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MtEPxP5HOLaP65T3ClRlc0x54UUAeJID
"""


# Diabetic Retinopathy ResNetCAM


"""**Importing the required libraries**"""

import os
import gc
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow import set_random_seed
import tensorflow as tf
import keras
import cv2
from PIL import Image
from keras.applications.resnet50 import ResNet50
from keras.applications.resnet50 import preprocess_input, decode_predictions
from keras.preprocessing import image
from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D
from keras.layers import Flatten, Dense
from keras.models import Model,Sequential
from keras.layers import BatchNormalization
from keras.optimizers import SGD,Adam
from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from keras.layers import Input
from keras import backend as K

"""**Declaring the constansts**"""

input_file=sys.argv[1]
#output_file=sys.argv[2]

SEED = 4199
np.random.seed(SEED)
set_random_seed(SEED)
IMG_DIM = 224
BATCH_SIZE = 32
CHANNEL_SIZE = 3
NUM_EPOCHS = 20
CLASSS = {0: "No DR", 1: "Mild", 2: "Moderate", 3: "Severe", 4: "Proliferative DR"}
NUM_CLASSS = 5

"""**Loading the dataframes**"""

# Function to show one image

def draw_img(imgs, target_dir, class_label='0'):
    for row in enumerate(imgs.iterrows()):
        name = row[1][1]['id_code'] + '.jpeg'
        print(name)
        plt.figure(figsize=(3,2))
        img = plt.imread(dir_path + target_dir + '/' + name)
        plt.imshow(img)
        plt.title(class_label)
        plt.show()
        del img
        gc.collect()

"""**Showing randomly chosen Severe DR image one at a time** """

# Showing the class 3 image randomly


gc.collect()

"""**Split the train data into train and test(validation) set**"""

# !pip install -U imbalanced-learn


"""**Obervations:**
The differences between the classes are very minute and intricate in *some cases*, 
which is difficult to detect by human eyes. 
So to capture the intricacies we can consider using ResNet Network as 
it combines the information from different scales of the image and the 
1x1 convolution helps to detect the complex functions as well as it helps 
to reduce dimension.

**Defining the ResNet network**
"""

# input_tensor = Input(shape = (224, 224, 3))

# # create the base pre-trained model
# base_model = ResNet50(weights="imagenet", include_top=True, input_tensor=input_tensor)
# #base_model.load_weights('/content/drive/My Drive/Kaggle/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')

# # add a global spatial average pooling layer

# x = base_model.get_layer('avg_pool').output
# x = Flatten(name='flatten')(x)
# predictions = Dense(num_classes, activation='softmax', name='output_layer')(x)
# model = Model(inputs=image_input,outputs=predictions)

# # first: train only the top layers (which were randomly initialized)
# # i.e. freeze all convolutional InceptionV3 layers

# for layer in model.layers[:-1]:
# 	layer.trainable = False
    
# print(model.summary())

# [layer.trainable for layer in model.layers]


"""**GradCAM Models**"""

def load_image(path, target_size=(224, 224)):
    x = image.load_img(path, target_size=target_size)
    x = image.img_to_array(x)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)

    return x

def generate_gradcam(img_tensor, model, class_index, activation_layer):
    model_input = model.input

    y_c = model.outputs[0].op.inputs[0][0, class_index]

    A_k = model.get_layer(activation_layer).output

    get_output = K.function([model_input], [A_k, K.gradients(y_c, A_k)[0]])
    [conv_output, grad_val] = get_output([img_tensor])

    conv_output = conv_output[0]
    grad_val = grad_val[0]

    weights = np.mean(grad_val, axis=(0, 1))

    grad_cam = np.zeros(dtype=np.float32, shape=conv_output.shape[0:2])
    for k, w in enumerate(weights):
        grad_cam += w * conv_output[:, :, k]

    grad_cam = np.maximum(grad_cam, 0)

    return grad_cam, weights

def generate_cam(img_tensor, model, class_index, activation_layer):
    model_input = model.input

    A_k = model.get_layer(activation_layer).output

    get_output = K.function([model_input], [A_k])
    [conv_output] = get_output([img_tensor])

    conv_output = conv_output[0]

    weights = model.layers[-1].get_weights()[0][:, class_index]

    cam = np.zeros(dtype=np.float32, shape=conv_output.shape[0:2])
    for k, w in enumerate(weights):
        cam += w * conv_output[:, :, k]

    return cam, weights


"""**Load Model**"""


model = keras.models.load_model('models/resnet50_gradcam_final.h5')
print(model.summary())

"""**Testing one DR Gradcam**"""

img_width, img_height = 224,224

# Showing the class 3 image randomly

#img_path = 'test.jpeg'

img_path = input_file

img = load_image(path=img_path, target_size=(img_width, img_height))

preds = model.predict(img)
predicted_class = preds.argmax(axis=1)[0]
    
# decode the results into a list of tuples (class, description, probability)
# (one such list for each sample in the batch)
    
print("predicted top1 class:", predicted_class)
# print('Predicted:', decode_predictions(preds, top=1)[0])
    
conv_name = 'activation_49'
# conv_name = 'mixed10'
grad_cam, grad_val = generate_gradcam(img, model, predicted_class, conv_name)
cam, cam_weight = generate_cam(img, model, predicted_class, conv_name)

img = cv2.imread(img_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
img = cv2.resize(img, (img_width, img_height))

cam = cv2.resize(cam, (img_width, img_height))
plt.figure(0)
plt.imshow(img)
plt.imshow(cam, cmap="jet", alpha=.2)
plt.axis('off')
grad_cam = cv2.resize(grad_cam, (img_width, img_height))
plt.figure(1)
plt.imshow(img)
plt.imshow(grad_cam, cmap="jet", alpha=.2)
plt.axis('off')
plt.show()


